\chapter{Estado del Arte}\label{chapter:state-of-the-art}

Para abordar el problema de la reconstrucción y medición de lesiones, en nuestro caso úlceras del pie diabético, se ha realizado una consulta a la literatura científica disponible. En este capítulo se presentan algunas de las investigaciones revisadas.

El sistema propuesto puede ser subdividido en las siguentes etapas: (1) \textit{Captura de Imágenes RGB-D}, (2) \textit{Rastreo de objetos en imágenes RGB}, (3)
\textit{Segmentación}  y (4) \textit{Reconstrucción 3D} de úlceras del pie diabético. Siendo este el caso, no solo se analizarán las publicaciones de sistemas similares al desarrollado, también se mostrarán aquellas que tratan con los procesos (2), (3) y (4) de forma independiente.

\section{Sistemas similares}

En~\cite{filko2018wound} explora la viabilidad de utilizar una cámara RGB-D para detectar, segmentar, reconstruir y medir lesiones. La herida se detecta implementando un algoritmo del vecino más cercano (KNN por sus siglas en inglés) en los histogramas de color generados a partir de la imagen. El procedimiento de segmentación de heridas propuesto extrae el contorno de la herida utilizando información visual y geométrica de la superficie. Se utiliza un procedimiento comparable a \textit{KinectFusion}~\cite{izadi2011kinectfusion} para la reconstrucción 3D de la herida. Todo el sistema se realiza en CUDA~\footnote{CUDA es una plataforma de computación paralela y de interfaces de aplicación de programa que permite a los softwares utilizar tipos de unidades gráficas para propósitos generales.}.

En~\cite{ching2022segm3d} se desarrolla un sistema de modelación y segmentación 3D de UPD a partir de la captura de una secuencia de imágenes RGB-D utilizando la cámara Kinect v1. La segmentación 3D se apoya en las máscaras obtenidas de la segmentación de las imágenes RGB. Los resultados derivan de ejecutar la reconstrucción utilizando dichas máscaras junto a los datos de profundidad. La segmentación 2D hace uso de la red neuronal UNet para cumplir la tarea.

En~\cite{chae2022generating} se introduce \textit{AiD Regen}, un sistema semiautomático que combina la segmentación semántica en 2D con la reconstrucción 3D. Utilizando DeepLabv3~\cite{chen2017rethinking}, un modelo basado en Redes Neuronales Convolucionales (RNC), usando las imágenes de profundidad de las cámaras \textit{TrueDepth} (que utilizan sensores de luz estructurada en lugar de LiDAR o vision estereoscópica) en dispositivos Apple.

En~\cite{mirzaalian2019measuring} se presenta un acercamiento sobre la medición de la lesión en 2 y 3 dimensiones. Para el procedimiento 2D, se toma una única foto que contiene una regla flexible de papel. La segmentación de la herida ocurre de manera semiautomática: primero se selecciona la región de interés definida por el usuario, dibujando un contorno alrededor y luego se procede a ejecutar una clasificación de Bosque Aleatorio (Random Forest, RF). Tras la segmentación, la evaluación se basa en estimación a escala local usando la regla. El acercamiento 3D cuenta con una reconstrucción que utiliza la técnica de Estructura a partir del Movimiento (\textit{Structure from Motion}, SfM). Para la segmentación 3D, se aplica a todas las imágenes el método de segmentación usado en el procedimiento 2D, obteniendo máscaras binarias; por último, se repite la reconstrucción a color de acuerdo con la secuencia de máscaras binarias que resulta en una superficie en escala de grises.

\section{Seguimiento de Objetos}

El seguimiento de objetos, a nivel abstracto, se puede realizar con uno de los dos enfoques existentes, (1) Seguimiento de un Solo Objeto (SOT), y (2) Seguimiento de Multiples Objetos (MOT). Como su nombre da a entender, SOT es cuando un objeto especifico se rastrea en un vídeo o conjunto de cuadros (\textit{frames}). De manera similar, el MOT es cuando varios objetos estan siendo rastreados simulataneamente en el mismo vídeo o conjunto de frames. Este último, por razones obvias, es mas complicado que SOT. A continuación se describen las investigaciones revisadas en este tema.

En el año 2015,~\cite{nam2016learning} propone un rastreador multidominio utilizando redes neuronales convolucionales: \textit{MDNet},abreviatura para \textit{Multi-Domain Convolutional Neural Network Tracker}. Es también el ganador del \textit{VOT2015 challenge}, competencia de desarrollo de algoritmos de seguimiento de objetos en el 2015, auspiciada por la Universidad de Ljubljana. \textit{MDNet} está compuesto de múltiples capas compartidas y ramas de capas específicas del dominio. Las capas convolucionales en la parte inferior están encargadas de aprender las características independientes del dominio, y esta extracción de caracterísicas se comparte para toda la secuencia de vídeo. En cuanto a la capa superior totalmente conectada, es única para cada cuadro y aprende las características específicas del dominio, es decir, las características abstractas de alto nivel inherentes al cuadro particular de la secuencia de vídeo en la que se está aplicando.

Luego, en 2017 se publica \textit{DeepSort}~\cite{wojke2017simple},uno de los rastreadores mas usado, el cual usa YOLO v3~\cite{redmon2018yolov3} para computar los cuadros delimitadores alrededor del objeto en videos. Es la extensión del  SORT (\textit{Simple Online and Realtime Tracking})~\cite{bewley2016simple}. Utiliza el filtro Kalman~\cite{welch1995introduction} del algoritmo SORT y utiliza un modelo de identificación llamado \textit{ReID} para vincular los cuadros delimitadores con las pistas estimadas de los objetos. En caso de que ninguna identificador (ID) coincida con la pista, al objeto y la pista se les asigna una nueva ID. \textit{DeepSort} permite rastrear objetos a través de períodos más prolongados de oclusión.

Este mismo año publican CSRT (Discriminative Correlation Filter with Channel and Spatial Reliability (CSR-DCF))~\cite{lunevzivc2018discriminative} que utiliza filtros de correlación discriminativa para el rastreo a corto plazo, introduce los mapas de confiabilidad espacial para ajustar el filtro a la parte del frame seleccionado. Esto permite ampliar la región de búsqueda y mejora el seguimiento de objetos no rectangulares. También posee gran precisión para vídeos con taza de frames más bajos ($25 fps$)

\section{Segmentación de UPD}

La segmentación de las lesiones se realiza principalmente de dos maneras. Existen variantes que aprovechan las características de profundidad una vez construido el modelo 3D, tal y como se menciona en~\cite{filko2018wound}. El enfoque empleado combina la segmentacion en 2D (solamente de las imágenes RGB), y la reconstrucción, aplicando las máscaras binarias resultantes para luego reconstruir la escena, un enfoque similar a lo propuesto en~\cite{mirzaalian2019measuring}. Por tanto, el estudio de la segmentación se enfocará en los métodos basados solo en imágenes RGB.

En~\cite{filko2018wound} se propone un método de segmentación temprana utilizando un algoritmo de vecinos mas cercanos.  Primeramente, se realiza un conjunto de datos con las imágenes de \textit{ground truth}, obteniendo de cada imagen ventanas de $n \times n$, y clasificándolas como lesión si la mayoría de sus píxeles ($> 50 \%$) pertenecen a una lesión. De estas imágenes se toma la concatenación de los histogramas de los canales de matiz y saturación del espacio HSL para realizar el algoritmo KNN.

En~\cite{seixas2015pattern} se emplean clasificadores estándares para segmentar la úlcera. Se extraen las características de color a nivel de píxel, el valor de la media de la vecindad del píxel y las diferencias entre los valores de los píxeles y las medias mencionadas. De forma similar, en~\cite{heras2022diabetic} se exploran distintos algoritmos de clasificación, tales como SVM, regresiones logísticas, entre otros; además, se exploran las características que mejoran el rendimiento de los algoritmos.  Luego de obtener la máscara de segmentación se posprocesa utilizando operaciones morfológicas.

En~\cite{malian2004medphos} el objetivo fue desarrollar métodos para segmentar, medir y caracterizar las heridas crónicas clínicamente presentadas a partir de imágenes fotográficas. El primer paso del método es generar un mapa de probabilidad Rojo-Amarillo-Negro-Blanco (RYKW, por sus siglas en inglés), que luego guía el proceso de segmentación utilizando un umbral óptimo o un crecimiento regional. Los mapas de probabilidad rojo, amarillo y negro están diseñados para manejar los tejidos de granulación, desprendimiento y necrótico, respectivamente; mientras que el mapa de probabilidad blanco es para detectar una etiqueta blanca que aparece en la fotografía con fines de calibración para la medición.

En~\cite{wang2015unified} se propone una estrategia basada en aprendizaje profundo, para ello utiliza una variante de red neuronal convolucional, \textit{ConvNet}, formada de 9 capas. Su propuesta difiere de los acercamientos tradicionales porque no necesita una secuencia de pasos como mejoramiento de las imágenes o extracción de características personalizadas, sino que realiza varios pasos al mismo tiempo.

Los enfoques basados en redes neuronales convolucionales son bastante utilizados para la tarea de segmentación. Una de las redes mas usadas es UNet[], pues esta no requiere grandes volumenes de informacion para entrenar. En~\cite{chino2020segmenting} se presenta ASURA (Sistema Automático de Diagnóstico sobre Regiones de Úlceras en la Piel), haciendo uso de UNet con ligeras modificaciones.

En~\cite{mahbod2021automatic} se propone un conjunto de redes neuronales convolucionales funcionando de ensemble para segmentar la zona de la UPD. Además utiliza técnicas de posprocesamiento para mejorar la máscara. Este trabajo se colocó en primera posición en \textit{DFU grand challenge} en 2021, un concurso de desarrollo de algoritmos de segmentación de úlceras.

\section{Reconstrucción 3D}

Dentro de este tópico se abordan los trabajos desarrollados para la reconstrucción 3D de escenas estáticas con imágenes RGB-D. En~\cite{zollhofer2018state} publicado en 2018, se detallan las diferentes técnicas existentes en dicho ámbito, esta subsección se desarrolla bajo los mismos criterios utilizados en su análisis.

Según~\cite{zollhofer2018state}, aunque existen múltiples algoritmos de reconstrucción RGB-D que giran en torno a este tipo de escenarios, la mayoría de los acercamientos cuentan con un flujo de procesamiento similar. En la primera etapa se realiza la estimación de la posición de la cámara, donde se computa la mejor transformación de alineación $T$ para el actual cuadro o imagen. Puede ser logrado cuadro-a-cuadro, cuadro-a-modelo o de manera global. Luego todos los puntos de este cuadro son transformados a partir de $T$ y mezclados al modelo en la etapa de fusión de mapas de profundidad.

\subsection{Estimación de la Posición de la Cámara}

Para la estimación de posición de la cámara en trabajos tempranos se idearon técnicas a posteriori u \textit{offline}, como variantes cuadro-a-cuadro del Algoritmo Iterativo de Puntos más Cercanos (ICP por sus siglas en inglés)~\cite{besl1992method, chen1992object} y se basaron en métricas de error punto-a-punto~\cite{chen1992object} o punto-a-plano~\cite{besl1992method}. Luego con el desarrollo de rápidas y eficientes variantes de ICP~\cite{rusinkiewicz2001efficient}, se hicieron posibles los escaneos en tiempo real~\cite{rusinkiewicz2002real}.

Las estrategias cuadro-a-cuadro provocan acumulación de desplazamiento sobre largas secuencias de imágenes; en consecuencia, se idearon seguimientos cuadro-a-modelo~\cite{chen2013scalable,izadi2011kinectfusion} para las reconstrucciones RGB-D en tiempo real u \textit{online}, basadas en el método ICP punto-a-plano descrito en~\cite{low2004linear}. A pesar de que estos reducen significativamente el desplazamiento del seguimiento temporal, no resuelven completamente la acumulación del error local.

A fin de aliviar los problemas que esto trae consigo, algoritmos para la optimización de la posición global fueron introducidos y primeramente aplicados en reconstrucciones a posteriori de escenas 3D~\cite{zhou2013dense,zhou2013elastic}. En~\cite{zhou2013dense} se producen reconstrucciones de alta calidad para sensores portátiles comerciales; utilizan puntos de interés para preservar detalles locales en combinación con optimización de la posición global para distribuir errores de alineación equitativamente sobre la escena. En un trabajo de continuaión~\cite{zhou2013elastic}, para incrementar aún más la fidelidad de la reconstrucción, se realiza un ajuste de paquete (\textit{bundle adjustment}) no rígido en fragmentos elásticos para lidiar con las distorsiones de bajas frecuencias de la cámara. El enfoque a posteriori propuesto en~\cite{choi2015robust} emplea optimización robusta de posición global basada en una línea de procesamiento para eliminar empaejamientos incorrectos y mejorar la calidad de la reconstrucción. Recientemente, en~\cite{dai2017bundlefusion} se habilitó la reconstrucción de consistencia global para velocidad de fotograma en tiempo real apoyado en ajuste de paquete \textit{online} y reintegración de superficies.

\subsection{Representación Geométrica y Fusión}

Principalmente existen dos diferentes representaciones para la acumulación de los datos RGB-D observados en un solo modelos 3D. El más usado es el almacenamiento de información en una retícula regular o jerárquica de vóxeles 3D. Alternativamente, el modelo puede ser almacenado como conjunto de puntos 3D acumulados.

Para la representación con vóxeles la investigación original de Curless y Levoy~\cite{curless1996volumetric} introdujo fusión volumétrica usando retículas regulares para almacenar una versión discreta de la Función Signada de Distancia (\textit{Signed Distance Function}, SDF) que representara el modelo. Fue primeramente adoptado por acercamientos en tiempo real~\cite{rusinkiewicz2002real} y luego por los métodos \textit{KinectFusion}~\cite{izadi2011kinectfusion}. Dado que los vóxeles cercanos a la superficie son de interés particular la Función Signada de Distancia Truncada (\textit{Truncated Signed Distance Function}, TSDF) es comúnmente usada.

Aunque no es posible en tiempo real, Fuhrmann y Goesele~\cite{fuhrmann2011fusion} introdujeron una estructura SDF jerárquica (\textit{Hierarchy SDF}, hSDF) usando una estructura de datos similar a un árbol octal (\textit{Octree}). En~\cite{zeng2012memory, zeng2013octree} se emplea una jerarquía fija de 4 niveles y almacenan el TSDF solamente en el mejor nivel. En~\cite{chen2013scalable} se propone una jerarquía similar de 3 niveles también con resolución fija. En~\cite{henry2013patch} se subdivide la escena en volúmenes de cuadros, cada uno compuesto por una retícula regular de vóxeles con tamaños y resoluciones arbitrarias. Una jerarquía extremadamente compacta fue presentada en~\cite{reichl2016memory}, donde solo se almacena una retícula binaria. Otra propuesta innovadora, fue el hash de vóxeles introducidos en~\cite{niessner2013real}.

Alternativamente a las representaciones basadas en vóxeles, el rango de imágenes adquiridas puede ser directamente almacenado y acumulado en un modelo basado en puntos o superficies~\cite{pfister2000surfels}. Esta estrategia es usada en múltiples reconstrucciones~\cite{keller2013real,whelan2015elasticfusion}.

